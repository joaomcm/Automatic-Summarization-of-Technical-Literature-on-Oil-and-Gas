{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We start by importing all relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk.data\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import WordPunctTokenizer,sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import codecs\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "from unidecode import unidecode\n",
    "from joblib import Parallel,delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(text):\n",
    "    \"\"\"This function removes all non-ascii characters from text and replaces them with their closest ascii representation\"\"\"\n",
    "    return unidecode(unicode(text, encoding = \"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we expand the set of stopwords in English to eliminate some very common words in papers, such as Fig, Table, Equation, Eq\n",
    "stop_words = list(set(stopwords.words('english')))\n",
    "stop_words.extend(['Fig','Fig.','Table','table','Equation','equation','Eq.','Eq','Figure','figure','below','follows'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We then proceed with one example before preprocessing the entire base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_list = pd.Series(sorted(glob.glob('/home/joao/Thesis/test_set/abridged/*.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = paper_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we then start tokenizing the text:\n",
    "# we then remove all non-ascii characters\n",
    "def get_ts_matrix(paper):\n",
    "    #opening example file\n",
    "    with open(paper,'rb') as f:\n",
    "        raw_text = f.read()\n",
    "    # removing all non-unicode characters: \n",
    "    raw_text = remove_non_ascii(raw_text)\n",
    "    # we start by removing all citations and things between parenthesis:\n",
    "    raw_text = re.sub(r'\\([^)]*\\)', '',raw_text)\n",
    "    this_file = paper[:-4].split('/')[-1]\n",
    "    sentences = sent_tokenize((raw_text))\n",
    "    tokenized = []\n",
    "    useful_sentences = []\n",
    "    for i in range(len(sentences)):\n",
    "        if(any(c.isalpha() for c in sentences[i])):\n",
    "            tokenized.append(WordPunctTokenizer().tokenize(sentences[i].strip()))\n",
    "            useful_sentences.append(sentences[i].strip())\n",
    "    sentences = useful_sentences\n",
    "\n",
    "    # We then create the term-sentence matrix from the cleaned up-text\n",
    "    sentences_df = pd.DataFrame(sentences)\n",
    "    sentences_df['filename'] = this_file\n",
    "    sentences_df['sentence_order'] = sentences_df.index.values\n",
    "    sentences_df.columns = ['sentence','filename','sentence_order']\n",
    "    full_tokenized = []\n",
    "    for i in tokenized:\n",
    "        full_tokenized.extend(i)\n",
    "\n",
    "    ts_matrix = pd.DataFrame(columns = sorted(set(full_tokenized)))\n",
    "    accumulator = []\n",
    "    accumulator.append(ts_matrix)\n",
    "    for i in range(len(tokenized)):\n",
    "        fdist = FreqDist(tokenized[i])\n",
    "        tmp = pd.DataFrame.from_dict(dict(fdist), orient = 'index')\n",
    "        tmp1 = tmp.reset_index()\n",
    "        tmp1.columns = ['word','count']\n",
    "        tmp1 = pd.pivot_table(tmp1, columns = 'word')\n",
    "        tmp1.index = [i]\n",
    "        accumulator.append(tmp1)\n",
    "    ts_matrix = pd.concat(accumulator, ignore_index = True)\n",
    "\n",
    "    # we then remove the stopwords:\n",
    "\n",
    "    stop_words = list(set(stopwords.words('english')))\n",
    "    stop_words.extend(['Fig','Fig.','fig','eq','Table','table','Equation','equation','Eq.','Eq','Figure','figure','below','follows'])   \n",
    "    ts_matrix = ts_matrix[ts_matrix.columns[~ts_matrix.columns.str.lower().isin(stop_words)]]\n",
    "    #adding the file for reference:\n",
    "    ts_matrix['this_file_name'] = this_file\n",
    "    ts_matrix['sentence_order'] = ts_matrix.index.values\n",
    "    ts_matrix = ts_matrix[list(ts_matrix.columns[ts_matrix.columns.str.isalpha()])+['this_file_name','sentence_order']]\n",
    "    rows_to_drop = ts_matrix.index[ts_matrix.drop(columns = ['this_file_name','sentence_order']).fillna(0).sum(axis =1) == 0]\n",
    "    sentence_bank = sentences_df.drop(index = rows_to_drop).reset_index(drop = True)\n",
    "    ts_matrix = ts_matrix.drop(index=  rows_to_drop).reset_index(drop = True)\n",
    "    # we finally eliminate all 2 letter words to avoid the influence of units of measure in the summarization:\n",
    "    ts_matrix = ts_matrix[ts_matrix.columns[ts_matrix.columns.str.len()>2]]\n",
    "    word_count = sentence_bank.sentence.str.split(' ').str.len()\n",
    "    ts_matrix_file = '/home/joao/Thesis/test_set/ts_matrices/' + this_file + '.p'\n",
    "    sentence_bank_file = '/home/joao/Thesis/test_set/sentence_banks/'+ this_file+ '.p'\n",
    "    word_counts = []\n",
    "    for i in sentence_bank.sentence:\n",
    "        word_counts.append(len(WordPunctTokenizer().tokenize(i.strip())))\n",
    "    ts_matrix['word_count'] = word_counts\n",
    "    # eliminating empty rows:\n",
    "    empty_rows = ts_matrix[ts_matrix.drop(columns = ['word_count','sentence_order','this_file_name']).sum(axis = 1) == 0].index\n",
    "    ts_matrix.drop(index = empty_rows, inplace = True)\n",
    "    sentence_bank.drop(index = empty_rows, inplace = True)\n",
    "    ts_matrix.reset_index(inplace = True, drop = True)\n",
    "    sentence_bank.reset_index(inplace = True, drop = True)\n",
    "    ts_matrix.to_pickle(ts_matrix_file)\n",
    "    sentence_bank.to_pickle(sentence_bank_file)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paralellizing the execution of the transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_list = pd.Series(sorted(glob.glob('/home/joao/Thesis/test_set/abridged/*.txt')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = Parallel(n_jobs = 8, verbose = 11)(delayed(get_ts_matrix)(paper) for paper in paper_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution time : 43.8s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modifying the function to get a tf_matrix for the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk.data\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import WordPunctTokenizer,sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import codecs\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "from unidecode import unidecode\n",
    "from joblib import Parallel,delayed\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    \"\"\"This function removes all non-ascii characters from text and replaces them with their closest ascii representation\"\"\"\n",
    "    return unidecode(unicode(text, encoding = \"utf-8\"))\n",
    "\n",
    "paper_list = pd.Series(sorted(glob.glob('/home/joao/Thesis/test_set/abridged/*.txt')))\n",
    "paper_list[0].split('/')[-1][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we then start tokenizing the text:\n",
    "# we then remove all non-ascii characters\n",
    "def get_ts_titles(paper):\n",
    "    #opening example file\n",
    "    raw_text = paper.split('/')[-1][:-4]\n",
    "    # removing all non-unicode characters: \n",
    "    raw_text = remove_non_ascii(raw_text)\n",
    "    # we start by removing all citations and things between parenthesis:\n",
    "    raw_text = re.sub(r'\\([^)]*\\)', '',raw_text)\n",
    "    this_file = paper[:-4].split('/')[-1]\n",
    "    sentences = sent_tokenize((raw_text))\n",
    "    tokenized = []\n",
    "    useful_sentences = []\n",
    "    for i in range(len(sentences)):\n",
    "        if(any(c.isalpha() for c in sentences[i])):\n",
    "            tokenized.append(WordPunctTokenizer().tokenize(sentences[i].strip()))\n",
    "            useful_sentences.append(sentences[i].strip())\n",
    "    sentences = useful_sentences\n",
    "\n",
    "    # We then create the term-sentence matrix from the cleaned up-text\n",
    "    sentences_df = pd.DataFrame(sentences)\n",
    "    sentences_df['filename'] = this_file\n",
    "    sentences_df['sentence_order'] = sentences_df.index.values\n",
    "    sentences_df.columns = ['sentence','filename','sentence_order']\n",
    "    full_tokenized = []\n",
    "    for i in tokenized:\n",
    "        full_tokenized.extend(i)\n",
    "\n",
    "    ts_matrix = pd.DataFrame(columns = sorted(set(full_tokenized)))\n",
    "    accumulator = []\n",
    "    accumulator.append(ts_matrix)\n",
    "    for i in range(len(tokenized)):\n",
    "        fdist = FreqDist(tokenized[i])\n",
    "        tmp = pd.DataFrame.from_dict(dict(fdist), orient = 'index')\n",
    "        tmp1 = tmp.reset_index()\n",
    "        tmp1.columns = ['word','count']\n",
    "        tmp1 = pd.pivot_table(tmp1, columns = 'word')\n",
    "        tmp1.index = [i]\n",
    "        accumulator.append(tmp1)\n",
    "    ts_matrix = pd.concat(accumulator, ignore_index = True)\n",
    "    # we then remove the stopwords:\n",
    "\n",
    "    stop_words = list(set(stopwords.words('english')))\n",
    "    stop_words.extend(['Fig','Fig.','fig','eq','Table','table','Equation','equation','Eq.','Eq','Figure','figure','below','follows'])   \n",
    "    ts_matrix = ts_matrix[ts_matrix.columns[~ts_matrix.columns.str.lower().isin(stop_words)]]\n",
    "    #adding the file for reference:\n",
    "    ts_matrix['this_file_name'] = this_file\n",
    "    ts_matrix['sentence_order'] = ts_matrix.index.values\n",
    "    ts_matrix = ts_matrix[list(ts_matrix.columns[ts_matrix.columns.str.isalpha()])+['this_file_name','sentence_order']]\n",
    "    rows_to_drop = ts_matrix.index[ts_matrix.drop(columns = ['this_file_name','sentence_order']).fillna(0).sum(axis =1) == 0]\n",
    "    sentence_bank = sentences_df.drop(index = rows_to_drop).reset_index(drop = True)\n",
    "    ts_matrix = ts_matrix.drop(index=  rows_to_drop).reset_index(drop = True)\n",
    "    # we finally eliminate all 2 letter words to avoid the influence of units of measure in the summarization:\n",
    "    ts_matrix = ts_matrix[ts_matrix.columns[ts_matrix.columns.str.len()>2]]\n",
    "    word_count = sentence_bank.sentence.str.split(' ').str.len()\n",
    "    ts_matrix_file = '/home/joao/Thesis/test_set/titles/' + this_file + '.p'\n",
    "    ts_matrix.to_pickle(ts_matrix_file)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = Parallel(n_jobs = 8, verbose = 11)(delayed(get_ts_titles)(paper) for paper in paper_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterizing the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "ts_matrix_list = sorted(glob.glob('/home/joao/Thesis/test_set/ts_matrices/*.p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "avg_word_count = []\n",
    "total_words = []\n",
    "for i in ts_matrix_list:\n",
    "    tmp = pd.read_pickle(i)\n",
    "    sentences.append(tmp.shape[0])\n",
    "    avg_word_count.append(tmp.word_count.mean())\n",
    "    total_words.append(tmp.word_count.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(sentences),np.std(sentences,ddof = 1),np.mean(avg_word_count),np.std(avg_word_count,ddof = 1),np.mean(total_words),np.std(total_words,ddof = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(109.18840579710145, 54.90292914138093, 22.93907341185208, 2.571579809536739, 2475.086956521739, 1213.5620968519086)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking sanity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge,FilesRouge\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "\n",
    "# we start by creating the summaries, i.e. picking the first k sentences until we have 250 words\n",
    "\n",
    "sentence_banks = sorted(glob.glob('/home/joao/Thesis/test_set/sentence_banks/*.p'))\n",
    "\n",
    "abstracts = []\n",
    "filenames = []\n",
    "\n",
    "for i in sentence_banks:\n",
    "    filenames.append(i.split('/')[-1])\n",
    "    sentence_bank = pd.read_pickle(i)\n",
    "    abstract = ''\n",
    "    for j in sentence_bank.sentence:\n",
    "        if(len((abstract+j).split(' '))<250):\n",
    "            abstract +=j\n",
    "        else:\n",
    "            break\n",
    "    abstracts.append(abstract)\n",
    "final_df = pd.DataFrame({'filenames':filenames,'abstracts':abstracts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:02<00:00, 25.22it/s]\n"
     ]
    }
   ],
   "source": [
    "results_df = final_df.copy()\n",
    "def remove_non_ascii(text):\n",
    "    \"\"\"This function removes all non-ascii characters from\n",
    "    text and replaces them with their closest ascii representation\"\"\"\n",
    "    return unidecode(unicode(text, encoding = \"utf-8\"))\n",
    "# we then load all summaries and candidate summaries:\n",
    "\n",
    "total_scores = []\n",
    "scores = []\n",
    "r1 = []\n",
    "r2 = []\n",
    "rl = []\n",
    "\n",
    "for i in tqdm(results_df.index):\n",
    "    ground_truth = ('/home/joao/Thesis/test_set/abstracts/ground_truths/'+ \n",
    "                    results_df.loc[i,'filenames'][:-2]+'.txt')\n",
    "    rouge = Rouge()\n",
    "    with open(ground_truth,'rb') as f:\n",
    "        ground_truth = f.read()\n",
    "    ground_truth = remove_non_ascii(ground_truth)\n",
    "    tmp_scores = rouge.get_scores(results_df.loc[i,'abstracts'],\n",
    "                                  ground_truth, avg = True)\n",
    "    r2.append(tmp_scores['rouge-2']['f'])\n",
    "    r1.append(tmp_scores['rouge-1']['f'])\n",
    "    rl.append(tmp_scores['rouge-l']['f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('r1', 0.2798802914809339, 0.0640168587924369)\n",
      "('r2', 0.07973435897110052, 0.04825397586421055)\n",
      "('rl', 0.23666681693479602, 0.06376390119510343)\n"
     ]
    }
   ],
   "source": [
    "print('r1',np.mean(r1),np.std(r1,ddof = 1))\n",
    "print('r2',np.mean(r2),np.std(r2, ddof = 1))\n",
    "print('rl',np.mean(rl),np.std(rl, ddof = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly selecting Sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:   38.0s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:   38.9s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   40.2s\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:   43.6s\n",
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed:   44.5s\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:   45.4s\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:   45.7s\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed:   45.8s\n",
      "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   46.6s\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:   49.5s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:   50.1s\n",
      "[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed:   50.9s\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:   51.3s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   51.8s\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:   52.0s\n",
      "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed:   52.2s\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:   53.0s\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed:   55.1s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:   56.2s\n",
      "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed:   56.9s\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:   57.2s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   57.9s\n",
      "[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed:   58.2s\n",
      "[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed:   58.9s\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:   59.5s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  86 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  87 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  91 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  92 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  93 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  95 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  99 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 101 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 102 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 103 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 106 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 107 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 108 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 111 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 115 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 117 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 118 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 119 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 123 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 125 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 126 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 127 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 131 tasks      | elapsed:  1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 133 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 134 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 135 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 139 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 140 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 142 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 143 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 145 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 147 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 148 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 150 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 151 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 153 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 155 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 156 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 159 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 161 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 162 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 163 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 166 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 167 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 169 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 171 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 174 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 175 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 178 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 179 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 181 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 182 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 183 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 185 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  2.6min finished\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge,FilesRouge\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel,delayed\n",
    "\n",
    "def remove_non_ascii(text):\n",
    "    \"\"\"This function removes all non-ascii characters from\n",
    "    text and replaces them with their closest ascii representation\"\"\"\n",
    "    return unidecode(unicode(text, encoding = \"utf-8\"))\n",
    "    \n",
    "\n",
    "# we start by creating the summaries, i.e. picking the first k sentences until we have 250 words\n",
    "\n",
    "sentence_banks = sorted(glob.glob('/home/joao/Thesis/test_set/sentence_banks/*.p'))\n",
    "\n",
    "\n",
    "\n",
    "R1 = []\n",
    "R2 = []\n",
    "RL = []\n",
    "    \n",
    "def evaluate_random_abstracts(k):\n",
    "    abstracts = []\n",
    "    filenames = []\n",
    "    for i in sentence_banks:\n",
    "        filenames.append(i.split('/')[-1])\n",
    "        sentence_bank = pd.read_pickle(i)\n",
    "        sentence_bank = sentence_bank.sample(frac = 1)\n",
    "        abstract = ''\n",
    "        for j in sentence_bank.sentence:\n",
    "            if(len((abstract+j).split(' '))<250):\n",
    "                abstract +=j\n",
    "            else:\n",
    "                break\n",
    "        abstracts.append(abstract)\n",
    "    final_df = pd.DataFrame({'filenames':filenames,'abstracts':abstracts})\n",
    "    results_df = final_df.copy()\n",
    "\n",
    "    # we then load all summaries and candidate summaries:\n",
    "\n",
    "    total_scores = []\n",
    "    scores = []\n",
    "    r1 = []\n",
    "    r2 = []\n",
    "    rl = []\n",
    "\n",
    "    for i in results_df.index:\n",
    "        ground_truth = ('/home/joao/Thesis/test_set/abstracts/ground_truths/'+ \n",
    "                        results_df.loc[i,'filenames'][:-2]+'.txt')\n",
    "        rouge = Rouge()\n",
    "        with open(ground_truth,'rb') as f:\n",
    "            ground_truth = f.read()\n",
    "        ground_truth = remove_non_ascii(ground_truth)\n",
    "        tmp_scores = rouge.get_scores(results_df.loc[i,'abstracts'],\n",
    "                                      ground_truth, avg = True)\n",
    "        r2.append(tmp_scores['rouge-2']['f'])\n",
    "        r1.append(tmp_scores['rouge-1']['f'])\n",
    "        rl.append(tmp_scores['rouge-l']['f'])\n",
    "    return np.mean(r1),np.std(r1,ddof = 1),np.mean(r2),np.std(r2, ddof = 1),np.mean(rl),np.std(rl, ddof = 1)\n",
    "\n",
    "final_results = Parallel(n_jobs = -1, verbose = 11)(delayed(evaluate_random_abstracts)(k) for k in range(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = []\n",
    "r1_std = []\n",
    "r2 = []\n",
    "r2_std = []\n",
    "rl = []\n",
    "rl_std = []\n",
    "for i in final_results:\n",
    "    r1.append(i[0])\n",
    "    r1_std.append(i[1])\n",
    "    r2.append(i[2])\n",
    "    r2_std.append(i[3])\n",
    "    rl.append(i[4])\n",
    "    rl_std.append(i[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('r1', 0.31365782578632995, 0.05878268006109875)\n",
      "('r2', 0.09443756653738461, 0.04765202054540724)\n",
      "('rl', 0.2660036938788816, 0.06054348730727893)\n"
     ]
    }
   ],
   "source": [
    "print('r1',np.mean(r1),np.mean(r1_std))\n",
    "print('r2',np.mean(r2),np.mean(r2_std))\n",
    "print('rl',np.mean(rl),np.mean(rl_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
